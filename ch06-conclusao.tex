\chapter{Conclusão}
\label{ch:08}

Este trabalho teve como principal objetivo estudar a questão do aprendizado de verbo irregulares do Português Brasileiro através da arquitetura \textit{Encoder-Decoder} (\cite{enc-dec:2014}, \cite{seq2seq:2014}). 

Para tanto, o escopo desta pesquisa foi restringido à 1$^{a}$ pessoa do singular, no tempo presente e modo indicativo. Em seguida, um corpus com 423 verbos foi criado e transcrito para uma representação fonética utilizando a metodologia desenvolvida no Capítulo \ref{ch:02}. O corpus criado foi primeiramente particionado segundo classes de irregularidade. No total, quinze classes irregulares foram formadas. A proporção de verbos regulares e irregulares no corpus montado foi de respectivamente 50.6\% e 49.4\%. Após a coleta e organizacão dos verbos, os mesmos foram pré-processados para serem introduzidos na camada de \textit{input} do modelo. 

O modelo \textit{Encoder-Decoder} foi configurado da seguinte maneira: As redes \textit{Encoder} e \textit{Decoder} são ambas do tipo LSTM's de dimensão latente de 256 nós. Para o treinamento foram utilizadas 300 épocas com lotes de 128 verbos por vez. O modelo foi otimizado com o algoritmo \textit{Adam} disponível na API do \textit{Keras} (\cite{chollet2015keras}) com hiperparâmetros pré-definidos na documentação. A função de custo utilizada foi a Entropia Cruzada Binária.

Para a avaliação do modelo construído, foi utilizada a técnica de validação cruzada chamada \textit{K-fold} (\cite{kfold:2018}), que permite que todos os verbos do corpus sejam testados pelo modelo. A métrica de avaliação escolhida foi a acurácia. Para considerar as variações possíveis durante os treinamentos, o algoritmo K-fold foi executado trinta vezes. Desse modo, foi possível estudar o comportamento médio do modelo nas diferentes classes do estudo.

A acurácia máxima atingida pelo modelo foi de 17\% considerando todos os verbos do corpus ($73/423$). Considerando apenas verbos regulares x verbos irregulares, o desempenho do modelo foi melhor no primeiro grupo, sendo as respectivas acurácias médias 17.88\% e 9.23\%. Considerando-se todas as classes do estudo, destaca-se a classe do verbo “botar” que, além de possuir alta proporção de exemplos no Corpus, é também a classe com menor comprimento médio. Ainda, foram observados alguns erros interessantes de troca de famílias nos verbos irregulares, como por exemplo: repetir (hepeti $\rightarrow$ hepEtu). Também ocorreram alguns erros de super-regularização (32). 

Durante a sessão de discussão (\ref{ch:05}), observamos que o tamanho do corpus obtido mostrou-se incompatível com a arquitetura \textit{Encoder-Decoder}. Entretanto, questiona-se se é razoável que um modelo computacional desenvolvido para esta tarefa necessite de um número muito maior de exemplos para o aprendizado. Por outro lado, observa-se que os módulos de pré e pós processamento dos verbos são independentes da arquitetura proposta. Neste sentido, pode-se argumentar que o resultado obtido nesta pesquisa não é conclusivo quanto ao desempenho do \textit{Encoder-Decoder}. 

Para pesquisas futuras, ficam algumas sugestões:

\begin{enumerate}

\item Obtenção de um corpus maior para a língua portuguesa
para que o algoritmo apresentado nesta pesquisa possa ser reavaliado;

\item Desenvolvimento de novos algoritmos de pré e pós processamento dos verbos. Outras representações vetoriais podem ser desenvolvidas. Uma opção é adicionar uma camada de \textit{embedding} (ref) antes da camada de \textit{input} do \textit{Encoder}; 

\item Realização de um teste psicolinguístico com verbos irregulares inventados para uma comparação entre as predições do modelo e as opiniões de falantes da língua;

\item Construção de um modelo do tipo \textit{Transformer} (\cite{Vaswani2017AttentionIA}). A arquitetura \textit{Transformer} é considerada a nova arquitetura estado-da-arte para modelos de tradução automática. 

\end{enumerate}

Para concluir, esperamos que a presente pesquisa tenha apresentado importantes contribuições para o tema do aprendizado de verbos irregulares dentro do domínio dos modelos de Redes Neurais Artificiais. No campo da Linguística, a construção de um corpus adequado e a execução desta tarefa para o Português Brasileiro foram certamente eventos inéditos nesta língua. 